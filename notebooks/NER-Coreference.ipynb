{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "# import en_core_web_md\n",
    "import neuralcoref\n",
    "  \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "# nlp = en_core_web_md.load()\n",
    " \n",
    "# sentence = \"Apple is looking at buying U.K. startup for $1 billion. Jane is looking for a job. She is a genious.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f951d532310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Dusted in an inch of pristine snow and with every railing, lattice, and fence strung with soft, twinkling lights, Historic Annapolis looked like a Christmas postcard, and in her present state of mind, it nearly drove her insane.\n",
    "Kate Warren hung on the horn of her rental car as yet another Annapolitan serenely slid into the intersection in front of her with locked brakes, and then grabbed the wheel with both hands to swerve around the hapless driver. Two decades living in the Northeast had taught her how to drive in snow, but it only took an hour back in Maryland to remind her that people in her home state had not received the same lessons. She floored the accelerator, easily parrying the resulting skid, and quickly slid past the other car. Better keep that guy as far behind as possible where he couldn't get her into any more trouble.\n",
    "That minor crisis averted, she grabbed the cigarette between her lips and puffed nervously, coughing just a little this time. The menthol taste was exquisite but felt forbidden, almost taboo. She'd bought the pack of Newports at a gas station not far from the airport. I can't believe I've become one of those people who smokes in a rental car, she thought idly as she pulled again on the cigarette, feeling her pulse slowing down in response. For that matter, she couldn't believe she'd gone back to cigarettes on a whim, a good two decades after quitting. No matter. With the way her life was going right now, a rental car cleaning fee was a small price to pay for a few moments of peace.\n",
    "It'd been years since she'd been back home, but everything had been instantly familiar the moment she turned off Route 50 and onto Rowe Boulevard heading into town. Sure, there were a few cosmetic changes here and there, but Annapolis, particularly the historic downtown district, was not really a town where a lot of things changed very fast. She had traversed the large circle circumscribing St. Anne's Church, the clock face on its red brick steeple glowing warmly through the swirling snow, and then easily found the turnoff to Duke of Gloucester Street riding the spine of the ridge leading downhill to the Chesapeake Bay. It all looked so sickeningly familiar. There was that street corner where Tony Johnson, her middle school boyfriend, had kissed her the first time, his clumsy hands feverishly exploring down the front of her shirt. There was the supermarket her mother had favored, often taking her daughter--never her precious boys, oh no, never them--with her on countless mind-numbingly boring grocery shopping trips. And there was the place where she had witnessed her step-father Ray drive his truck straight into a concrete barrier when his brakes gave out, killing him instantly. She imagined she could still see the scratches on the pavement, even fifteen years later, maybe even a darkened spot where that huge pool of blood had seeped into the concrete. It was getting too dark to tell, but she wasn't that eager to find out for sure anyway. \n",
    "The flood of memories had almost made her want to vomit. Then again, a lot of things made her vomit these days.\n",
    "Now she was slowing down as the intersection with Market Street came up, the big Nissan plowing through the thick slush like an Arctic research vessel through a field of ice floes. She turned right, the narrow street forcing her to slow down even more. The big car hummed quietly in between the rows of wooden Colonial houses, warm golden light filtering through the snowflakes and spilling out onto the snow-covered cobbles. The road crew hadn't made it to Market Street yet, so there was no slush here and only a few tire marks in the thickening snow. With more nasty weather on the way throughout the night, this was an evening most Annapolitans seemed to prefer spending at home.\n",
    "Her phone chirped, and she glanced at it, seeing its screen light up. A text from Chris. He was probably at La Guardia now, getting ready to fly down here. Unless there were more delays, of course. She'd call him back as soon as she pulled up in front of the house. Not far now.\n",
    "Glancing at the phone reminded her that she had two voice mails waiting as well. One each from Matt and Jake, those two precious boys, no doubt offering some lame excuse why they weren't here yet, and wouldn't be for days to come. Always trusting big sister Kate to be the responsible one. She snorted in derision.\n",
    "The car crested the little ridge, and then the street sloped sharply down towards Spa Creek, a black void at the end of the street behind a meager railing. This part of the street had some of the more spectacular old houses in the district, all of them tall and rickety wooden structures overlooking the chill waters of Annapolis's natural harbor.\n",
    "She took a deep breath and braked to a halt, steeling herself as another wave of memories crashed home. Vertigo grabbed an icy hold of her gut, and for a crazy moment, she considered flooring the accelerator and speeding down, down, down the narrow street. The big Nissan would punch through the railing at the bottom like a bowling ball through matchsticks, and then she'd be sinking into that dark, icy wetness. Maybe no one would even notice, a night like this?\n",
    "Instead, she carefully let up the brake and crawled down the street. It was running on the bottom of a natural gully sloping down the hill, with the houses on either side perched high on the gully's sides. This afforded each house a magnificent view of the harbor, but left no room for driveways, so people parked their cars on the curb in front of their house. She guessed people in Colonial times had had little use of cars.\n",
    "At this time of night, the whole street was filled with parked cars, and her heart sank as she realized she would have to drive back up the hill and find a free spot far away from the house. The prospect of walking just a few hundred yards on uneven Annapolis cobbles in wintry darkness in her condition was decidedly unpleasant.\n",
    "Then she saw that there was a big gap right in front of the house, as if a protective force field was projecting from the house itself, and realized that it shouldn't have surprised her. She remembered that it had been the same when she had been living at home. It was almost like the gap that schooling fish leave around a reef shark--after a few years, all the neighbors along the south end of Market Street had known to steer clear of the angry old widow in the purple house.\n",
    "Protective force field or not, it was a welcome sight at this hour, and she easily parallel parked the car with plenty of space left for Chris's rental, whenever he would show up. Then she dragged a last time on her cigarette and half-heartedly blew smoke out the cracked window before closing it, turning off the ignition, and getting out of the car. \n",
    "Her first thought was how silent it was with the car's engine and radio off. Her second was that it was cold, much colder than mere temperature had suggested. With one hand, she dragged her thick parka closed against the damp chill of the Chesapeake stealing into her bones, and with the other, she waved the remnants of the smoke out of the car and dropped the butt of the cigarette in the gutter.\n",
    "And froze.\n",
    "An elderly lady, diminutive but ramrod-straight figure embalmed in a downy parka that made her look twice her actual size, was staring at Kate from the curb. A terrier, fur the color of midnight and encased in a coat of the same color and cut as his owner, was straining at his leash and looking back questioningly over his shoulder at his owner, who must have stopped dead in her tracks. The yellow light shining down from the tired old lamppost above was feeble, but enough to reveal the old woman's horrified and disgusted look framed by the furlined hood. \n",
    "Kate hurriedly took a step back into the shelter of the car, trying to shield her belly. At close to seven months, it was a mostly futile gesture, and she knew it.\n",
    "\"Smoking is bad for the baby, you know, young lady,\" the old lady said primly in a reedy voice that cut through the night unpleasantly. \"And it's bad for you, too.\"\n",
    "\"I know, thank you,\" Kate said, feeling her cheeks start to burn like a school girl's, and hating herself for it even if it was too dark for anyone to see it. \"It was my friend's cigarette, not mine,\" she continued lamely.\n",
    "\"Hmmpf,\" the old lady said, putting her nose up. \"Come on, Skippy, time to go.\"\n",
    "The terrier yapped eagerly in agreement, and then continued to pull his owner up the hill. As the deadened footsteps faded away, Kate sighed in relief and leaned against the car, feeling the blush fading as her pulse stabilized again. Intruding old bitch, she thought with heat that surprised herself. You should mind your own business. That made her feel a little better.\n",
    "On the plus side, she wasn't cold anymore. She took a moment to steady her breathing, then glanced up at the house above her. As always, it loomed above her, a rickety wooden colossus of two stories and with a pointy tower rising another level. Perched on the ridge lining Market Street, it looked like a gangly giant leaning over to grab her.\n",
    "She shivered involuntarily, feeling another wave of memories rising up in her gorge, and instead fished her phone out of her pocket to stave off the onslaught.\n",
    "Chris's text was written in his usual clipped and businesslike language. \"At gate. Takeoff in thirty, weather willing. Arrive Annapolis 10pm. Call if U can.\"\n",
    "She tapped the call button and waited as she was connected, leaning against the car with snow falling peacefully all around her. The memory of the condemning old lady was fading just as quickly as her footsteps were being carefully concealed by big woolly flakes.\n",
    "\"Hey you,\" Chris said. He sounded tired. \"You there yet?\"\n",
    "\"Hey hon,\" she said. \"Yep. Just got here. It's snowing here too, maybe even worse than in New York.\"\n",
    "\"How's the baby?\" he said. \"And you? How are you feeling?\"\n",
    "\"Good,\" she lied. \"Tired. The baby is fine, too. She says hi.\"\n",
    "He actually laughed at that. \"Hey baby, daddy's on the way. Stay put and take care of mommy.\"\n",
    "She smiled, knowing he couldn't see it. \"Speaking of which, flight's still on for seven?\"\n",
    "\"Yes, they're getting ready to board us now, so it's looking pretty promising this time around.\"\n",
    "She nodded, grunted approvingly. \"So what about you, honey? You okay? You sound a little tired.\"\n",
    "\"The flight from Paris was a bitch,\" he admitted. \"This return trip was not exactly planned to the nines.\"\n",
    "\"And the partners? How are they taking this, on top of everything else?\" She couldn't quite erase the uncertainty from her own voice, and hated herself for it. Top grades all through school, double Ivy league degrees, and now the youngest partner in history at Cumberland and McDonough, a top Manhattan law firm, and a woman to boot, but she still felt like she was being sent to the principal's office whenever the partners--the other partners, which included Chris--were discussed.\n",
    "\"'Everything else', what's that supposed to mean?\" he said sharply with that annoying lawyerly way he had.\n",
    "She grunted. She guessed she had the same lawyerly way herself. \"You know what,\" she said, and cupped her free hand around her belly. Announcing her pregnancy at the partner's meeting last month--in fact, her first partner's meeting, period--had been something of a bomb shell, at least in her own mind, and she was sure they were all talking about her behind her back.\n",
    "\"Yes, I guess I do know,\" he said, softening. \"They understand, of course they understand.\"\n",
    "\"I bet that old gargoyle McDonough has had plenty to say about it,\" she said darkly. Chris had told her Melvin McDonough, one of the original founders of the firm, had been her most vocal opponent when the issue of her promotion had been discussed. She was sure it was because she was a woman. \"How he thought I was way past having babies, and how I'd turn into the mothering type, and all that crap.\"\n",
    "He chuckled. \"I bet, but not to my face. Don't worry about it, there's nothing he can do to you now.\"\n",
    "\"I guess not,\" she muttered and stamped her feet. She was getting cold again.\n",
    "\"Wait, are you still outside in the snow?\" he said in mock outrage. \"Let me guess, you're stalling from going into the house, so instead you're standing out there in the cold talking to me about law firm politics.\"\n",
    "She snorted humorlessly. \"Guilty as charged, counselor.\"\n",
    "He chuckled, and then suddenly grew serious. \"Listen, I know this must be hard,\" he said. \"Why don't you just find a coffee shop that's open late, or some cozy restaurant, and just hang out until I get there?\" His voice brightened as he got another idea. \"Or why not just take into a hotel, we deal with this in the morning? No way we want to stay in that spooky old house tonight anyway, am I right?\"\n",
    "She huffed. \"I spent fifteen years of my life in that spooky old house, you know. It's just a house. In fact, it's my house now. Mine and Jake's and Matt's house, that is,\" she corrected herself primly.\n",
    "He sighed audibly. \"Fine,\" he said, sounding defeated. She knew that he had never liked her family's old house on Market Street; in fact, had never much liked her family at all. Except her brothers, who were both likable enough, even if she privately felt they were pretty forgettable as well. \"I'll see you around ten. Hey, I gotta go, looks like they're starting to board now. Love you.\"\n",
    "\"Love you,\" she responded automatically, and then felt a twinge of unease as he hung up. She let the phone fall from her ear as she turned over the phrase in her head, absently staring at the screen glowing like a precious jewel in the dim night.\n",
    "Together for twelve years, and married for ten, all loving and stable throughout that whole time. Now since being hit with a surprise pregnancy only seven months ago, a lot of things she had been taking for granted were starting to no longer be true. Like her love for Chris. \n",
    "Why was she feeling this way? Wasn't pregnant couples supposed to grow stronger in their relationship, not weaker? And who would ever consider divorcing her husband of ten years, as a little voice kept whispering to her late at night, just when they finally had managed to conceive after all the medical options had failed?\n",
    "My mother, she thought bitterly, that's who. Her mother, who had forced a divorce on her poor father when she was six months pregnant with Kate herself. Her father, who had died, certainly of a fatal fall from a ladder, and perhaps of grief from being estranged from his daughter only a month before she was born.\n",
    "Actually, it wasn't that she didn't love Chris anymore. She did, she loved him dearly in that familiar and comfortable way that established couples do, where most of the thrill has worn away but what remains is a deep friendship and a fundamental understanding for each other. It was more of an impending feeling of doom that had been growing on her, like that little voice that kept telling her that she couldn't stay with him, that it somehow--impossibly--wouldn't be safe. As if he and the baby wouldn't be good together, even if she knew perfectly well that Chris would make a wonderful father. She couldn't quite put her feelings into words, but she felt it at the core of her being so strongly that she surreptitiously had started to look up divorce attorneys.\n",
    "Enough. She shook her head. Chris was right, she was stalling. This was a problem for another day. With an effort, she lifted her gaze from her phone screen, now beaded with little droplets of melting snow, to look at the dark house looming over her beyond a veil of swirling flurries. With its dark windows and gap-toothed front porch, it felt like it was leering at her.\n",
    "The problem at hand was her mom, she reminded herself. Her mom, who was now dead. And it was time to take care of the mess she had left behind.\n",
    "#\n",
    "\"Hi mom,\" she had said lamely when her mother had answered on the second ring.\n",
    "That had only been a week ago, and her mother had sounded her usual cold and detached self. Kate knew her mother didn't have a cellphone, and had been anticipating a long wait until the older woman had made it to her rotary phone in the parlor. Clearly she had either been sitting by the old Bakelite monstrosity, or had had no difficulties getting to it quickly.\n",
    "\"Well, well,\" the crisp voice, with just a hint of an old-person quake, came back through Kate's phone. \"If it isn't the long-lost daughter. Hello, dear, nice of you to take some time out of your important life to talk to your old mother.\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraph = '''The Census Bureau released two important sets of data last week that have big implications for American politics — and that challenge some prevailing assumptions for both Democrats and Republicans.\n",
    "# The first set of data lays out long-term demographic trends widely thought to favor Democrats: Hispanics, Asian-Americans and multiracial voters grew as a share of the electorate over the last two presidential races, and white voters — who historically tend to back the G.O.P. — fell to 71 percent in 2020 from 73 percent in 2016.\n",
    "# The other data set tells a second story. Population growth continues to accelerate in the South and the West, so much so that some Republican-leaning states in those regions are gaining more Electoral College votes. The states won by President Biden will be worth 303 electoral votes, down from 306 electoral votes in 2020. The Democratic disadvantage in the Electoral College just got worse again.\n",
    "#             '''\n",
    "# paragraph = '''Dusted in an inch of pristine snow and with every railing, lattice, and fence strung with soft, twinkling lights, Historic Annapolis looked like a Christmas postcard, and in her present state of mind, it nearly drove her insane.\n",
    "# Kate Warren hung on the horn of her rental car as yet another Annapolitan serenely slid into the intersection in front of her with locked brakes, and then grabbed the wheel with both hands to swerve around the hapless driver. Two decades living in the Northeast had taught her how to drive in snow, but it only took an hour back in Maryland to remind her that people in her home state had not received the same lessons. She floored the accelerator, easily parrying the resulting skid, and quickly slid past the other car. Better keep that guy as far behind as possible where he couldn't get her into any more trouble.\n",
    "#             '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Harry Potter has been spending another unhappy summer with the Dursleys. When Aunt Marge Dursley insults his parents, he loses his temper and accidentally causes her to inflate like a balloon and float away. Fed up, Harry then flees the Dursleys with his broom and trunk. The Knight Bus arrives and takes Harry to the Leaky Cauldron, where he is pardoned by Minister for Magic Cornelius Fudge for using magic outside of Hogwarts. After reuniting with his best friends Ron Weasley and Hermione Granger, Harry learns that Sirius Black, a convicted supporter of the dark wizard Lord Voldemort, has escaped Azkaban prison and intends to kill him.\n",
    "\n",
    "The trio return to Hogwarts for the school year on the Hogwarts Express train, which is suddenly boarded by dementors, ghostly prison guards that are searching for Black. One enters the trio's compartment, causing Harry to pass out, but new Defence Against the Dark Arts teacher Remus Lupin repels the dementor with a Patronus Charm. At Hogwarts, headmaster Albus Dumbledore announces that dementors will be guarding the school until Black is captured. Hogwarts groundskeeper Rubeus Hagrid is announced as the new Care of Magical Creatures teacher; his first class goes badly when Draco Malfoy deliberately provokes the hippogriff Buckbeak, who then attacks him. Draco exaggerates his injury, and his father Lucius Malfoy later has Buckbeak sentenced to death.\n",
    "\n",
    "The Fat Lady's portrait, which guards the Gryffindor rooms, is found ruined and empty. \n",
    "Terrified and hiding in another painting, she tells Dumbledore that Black has entered the castle. During a stormy Quidditch match against Hufflepuff, dementors attack Harry, causing him to fall off his broomstick which lands at the Whomping Willow, where it is destroyed. At Hogsmeade, Harry is shocked to learn that not only had Sirius been his father's best friend and apparently betrayed them to Voldemort, but is also Harry's godfather. Lupin privately teaches Harry to defend himself against dementors using the Patronus Charm.\n",
    "\n",
    "After Harry, Ron, and Hermione witness Buckbeak's apparent execution, Ron's pet rat Scabbers bites him and escapes. When Ron gives chase, a large dog appears and drags both Ron and Scabbers into a hole at the Whomping Willow's base. This leads the trio to an underground passage to the Shrieking Shack, where they discover that the dog is actually Sirius, who is an Animagus. Lupin arrives and embraces Sirius as an old friend. He admits to being a werewolf, and explains that Sirius is innocent. Sirius was falsely accused of betraying the Potters to Voldemort, as well as murdering twelve Muggles and their mutual friend, Peter Pettigrew. It is revealed that Scabbers is actually Pettigrew, an Animagus who betrayed the Potters and committed the murders.\n",
    "\n",
    "Severus Snape arrives to apprehend Black but Harry knocks him unconscious with the Expelliarmus spell. After forcing Pettigrew back into human form, Lupin and Sirius prepare to kill him, but Harry convinces them to turn Pettigrew over to the dementors.\n",
    "\n",
    "As the group departs, the full moon rises and Lupin transforms into a werewolf. Sirius transforms into his dog form to fight him off. In the midst of the chaos, Pettigrew transforms back into a rat and escapes. Harry and Sirius are attacked by dementors, and Harry sees a figure in the distance save them by casting a powerful Patronus spell. He believes the mysterious figure is his deceased father before passing out. He awakens to discover that Sirius has been captured and sentenced to the Dementor's Kiss.\n",
    "\n",
    "Acting on Dumbledore's advice, Harry and Hermione travel back in time using Hermione's Time Turner, and watch themselves and Ron repeat the night's events. They save Buckbeak from execution and witness the Dementors overpower Harry and Sirius. The present Harry realises that it was actually himself who conjured the Patronus, and does so again. Harry and Hermione rescue Sirius, who escapes with Buckbeak. Exposed as a werewolf, Lupin resigns from teaching to prevent an uproar from parents. He also returns the Marauder's Map to Harry, as he no longer has the authority to confiscate contraband. Sirius sends Harry a Firebolt broom, and he happily takes it for a ride.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Mr. and Mrs. Dursley, of number four, Privet Drive, \n",
    "were proud to say that they were perfectly normal, \n",
    "thank you very much. They were the last people you’d \n",
    "expect to be involved in anything strange or \n",
    "mysterious, because they just didn’t hold with such \n",
    "nonsense. \n",
    "\n",
    "Mr. Dursley was the director of a firm called \n",
    "Grunnings, which made drills. He was a big, beefy \n",
    "man with hardly any neck, although he did have a \n",
    "very large mustache. Mrs. Dursley was thin and \n",
    "blonde and had nearly twice the usual amount of \n",
    "neck, which came in very useful as she spent so \n",
    "much of her time craning over garden fences, spying \n",
    "on the neighbors. The Dursley s had a small son \n",
    "called Dudley and in their opinion there was no finer \n",
    "boy anywhere. \n",
    "\n",
    "The Dursleys had everything they wanted, but they \n",
    "also had a secret, and their greatest fear was that \n",
    "somebody would discover it. They didn’t think they \n",
    "could bear it if anyone found out about the Potters. \n",
    "Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t \n",
    "\n",
    "Page | 2 Harry Potter and the Philosophers Stone - J.K. Rowling \n",
    "\n",
    "\n",
    "\n",
    "met for several years; in fact, Mrs. Dursley pretended \n",
    "she didn’t have a sister, because her sister and her \n",
    "good-for-nothing husband were as unDursleyish as it \n",
    "was possible to be. The Dursleys shuddered to think \n",
    "what the neighbors would say if the Potters arrived in \n",
    "the street. The Dursleys knew that the Potters had a \n",
    "small son, too, but they had never even seen him. \n",
    "\n",
    "This boy was another good reason for keeping the \n",
    "Potters away; they didn’t want Dudley mixing with a \n",
    "child like that. \n",
    "\n",
    "When Mr. and Mrs. Dursley woke up on the dull, gray \n",
    "Tuesday our story starts, there was nothing about the \n",
    "cloudy sky outside to suggest that strange and \n",
    "mysterious things would soon be happening all over \n",
    "the country. Mr. Dursley hummed as he picked out \n",
    "his most boring tie for work, and Mrs. Dursley \n",
    "gossiped away happily as she wrestled a screaming \n",
    "Dudley into his high chair. \n",
    "\n",
    "None of them noticed a large, tawny owl flutter past \n",
    "the window. \n",
    "\n",
    "At half past eight, Mr. Dursley picked up his \n",
    "briefcase, pecked Mrs. Dursley on the cheek, and \n",
    "tried to kiss Dudley good-bye but missed, because \n",
    "Dudley was now having a tantrum and throwing his \n",
    "cereal at the walls. “Little tyke,” chortled Mr. Dursley \n",
    "as he left the house. He got into his car and backed \n",
    "out of number four’s drive. \n",
    "\n",
    "It was on the corner of the street that he noticed the \n",
    "first sign of something peculiar — a cat reading a \n",
    "map. For a second, Mr. Dursley didn’t realize what he \n",
    "had seen — then he jerked his head around to look \n",
    "again. There was a tabby cat standing on the corner \n",
    "of Privet Drive, but there wasn’t a map in sight. What \n",
    "could he have been thinking of? It must have been a \n",
    "trick of the light. Mr. Dursley blinked and stared at \n",
    "Page | 3 Harry Potter and the Philosophers Stone - J.K. Rowling \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "the cat. It stared back. As Mr. Dursley drove around \n",
    "the corner and up the road, he watched the cat in his \n",
    "mirror. It was now reading the sign that said Privet \n",
    "Drive — no, looking at the sign; cats couldn’t read \n",
    "maps or signs. Mr. Dursley gave himself a little shake \n",
    "and put the cat out of his mind. As he drove toward \n",
    "town he thought of nothing except a large order of \n",
    "drills he was hoping to get that day. \n",
    "\n",
    "But on the edge of town, drills were driven out of his \n",
    "mind by something else. As he sat in the usual \n",
    "morning traffic jam, he couldn’t help noticing that \n",
    "there seemed to be a lot of strangely dressed people \n",
    "about. People in cloaks. Mr. Dursley couldn’t bear \n",
    "people who dressed in funny clothes — the getups \n",
    "you saw on young people! He supposed this was some \n",
    "stupid new fashion. He drummed his fingers on the \n",
    "steering wheel and his eyes fell on a huddle of these \n",
    "weirdos standing quite close by. They were whispering \n",
    "excitedly together. Mr. Dursley was enraged to see \n",
    "that a couple of them weren’t young at all; why, that \n",
    "man had to be older than he was, and wearing an \n",
    "emerald-green cloak! The nerve of him! But then it \n",
    "struck Mr. Dursley that this was probably some silly \n",
    "stunt — these people were obviously collecting for \n",
    "something ... yes, that would be it. The traffic moved \n",
    "on and a few minutes later, Mr. Dursley arrived in the \n",
    "Grunnings parking lot, his mind back on drills. \n",
    "\n",
    "Mr. Dursley always sat with his back to the window in \n",
    "his office on the ninth floor. If he hadn’t, he might \n",
    "have found it harder to concentrate on drills that \n",
    "morning. He didn’t see the owls swooping past in \n",
    "broad daylight, though people down in the street did; \n",
    "they pointed and gazed open-mouthed as owl after \n",
    "owl sped overhead. Most of them had never seen an \n",
    "owl even at nighttime. Mr. Dursley, however, had a \n",
    "perfectly normal, owl-free morning. He yelled at five \n",
    "different people. He made several important telephone'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../story1.txt\")\n",
    "paragraph = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = paragraph.replace(u'\\xa0',u' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "for sent in doc.sents:\n",
    "    sents.append(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dusted in an inch of pristine snow and with every railing, lattice, and fence strung with soft, twinkling lights, Historic Annapolis looked like a Christmas postcard, and in her present state of mind, it nearly drove her insane.\\n',\n",
       " 'Kate Warren hung on the horn of her rental car as yet another Annapolitan serenely slid into the intersection in front of her with locked brakes, and then grabbed the wheel with both hands to swerve around the hapless driver.',\n",
       " 'Two decades living in the Northeast had taught her how to drive in snow, but it only took an hour back in Maryland to remind her that people in her home state had not received the same lessons.',\n",
       " 'She floored the accelerator, easily parrying the resulting skid, and quickly slid past the other car.',\n",
       " \"Better keep that guy as far behind as possible where he couldn't get her into any more trouble.\\n\",\n",
       " 'That minor crisis averted, she grabbed the cigarette between her lips and puffed nervously, coughing just a little this time.',\n",
       " 'The menthol taste was exquisite but felt forbidden, almost taboo.',\n",
       " \"She'd bought the pack of Newports at a gas station not far from the airport.\",\n",
       " \"I can't believe I've become one of those people who smokes in a rental car, she thought idly as she pulled again on the cigarette, feeling her pulse slowing down in response.\",\n",
       " \"For that matter, she couldn't believe she'd gone back to cigarettes on a whim, a good two decades after quitting.\",\n",
       " 'No matter.',\n",
       " 'With the way her life was going right now, a rental car cleaning fee was a small price to pay for a few moments of peace.\\n',\n",
       " \"It'd been years since she'd been back home, but everything had been instantly familiar the moment she turned off Route 50 and onto Rowe Boulevard heading into town.\",\n",
       " 'Sure, there were a few cosmetic changes here and there, but Annapolis, particularly the historic downtown district, was not really a town where a lot of things changed very fast.',\n",
       " \"She had traversed the large circle circumscribing St. Anne's Church, the clock face on its red brick steeple glowing warmly through the swirling snow, and then easily found the turnoff to Duke of Gloucester Street riding the spine of the ridge leading downhill to the Chesapeake Bay.\",\n",
       " 'It all looked so sickeningly familiar.',\n",
       " 'There was that street corner where Tony Johnson, her middle school boyfriend, had kissed her the first time, his clumsy hands feverishly exploring down the front of her shirt.',\n",
       " 'There was the supermarket her mother had favored, often taking her daughter--',\n",
       " 'never her precious boys,',\n",
       " 'oh no, never them--with her on countless mind-numbingly boring grocery shopping trips.',\n",
       " 'And there was the place where she had witnessed her step-father Ray',\n",
       " 'drive his truck straight into a concrete barrier when his brakes gave out, killing him instantly.',\n",
       " 'She imagined she could still see the scratches on the pavement, even fifteen years later, maybe even a darkened spot where that huge pool of blood had seeped into the concrete.',\n",
       " \"It was getting too dark to tell, but she wasn't that eager to find out for sure anyway. \\n\",\n",
       " 'The flood of memories had almost made her want to vomit.',\n",
       " 'Then again, a lot of things made her vomit these days.\\n',\n",
       " 'Now she was slowing down as the intersection with Market Street came up, the big Nissan plowing through the thick slush like an Arctic research vessel through a field of ice floes.',\n",
       " 'She turned right, the narrow street forcing her to slow down even more.',\n",
       " 'The big car hummed quietly in between the rows of wooden Colonial houses, warm golden light filtering through the snowflakes and spilling out onto the snow-covered cobbles.',\n",
       " \"The road crew hadn't made it to Market Street yet, so there was no slush here and only a few tire marks in the thickening snow.\",\n",
       " 'With more nasty weather on the way throughout the night, this was an evening',\n",
       " 'most Annapolitans seemed to prefer spending at home.\\n',\n",
       " 'Her phone chirped, and she glanced at it, seeing its screen light up.',\n",
       " 'A text from Chris.',\n",
       " 'He was probably at La Guardia now, getting ready to fly down here.',\n",
       " 'Unless there were more delays, of course.',\n",
       " \"She'd call him back as soon as she pulled up in front of the house.\",\n",
       " 'Not far now.\\n',\n",
       " 'Glancing at the phone reminded her that she had two voice mails waiting as well.',\n",
       " \"One each from Matt and Jake, those two precious boys, no doubt offering some lame excuse why they weren't here yet, and wouldn't be for days to come.\",\n",
       " 'Always trusting big sister Kate to be the responsible one.',\n",
       " 'She snorted in derision.\\n',\n",
       " 'The car crested the little ridge, and then the street sloped sharply down towards Spa Creek, a black void at the end of the street behind a meager railing.',\n",
       " \"This part of the street had some of the more spectacular old houses in the district, all of them tall and rickety wooden structures overlooking the chill waters of Annapolis's natural harbor.\\n\",\n",
       " 'She took a deep breath and braked to a halt, steeling herself as another wave of memories crashed home.',\n",
       " 'Vertigo grabbed an icy hold of her gut, and for a crazy moment, she considered flooring the accelerator and speeding down, down, down the narrow street.',\n",
       " \"The big Nissan would punch through the railing at the bottom like a bowling ball through matchsticks, and then she'd be sinking into that dark, icy wetness.\",\n",
       " 'Maybe no one would even notice, a night like this?\\n',\n",
       " 'Instead, she carefully let up the brake and crawled down the street.',\n",
       " \"It was running on the bottom of a natural gully sloping down the hill, with the houses on either side perched high on the gully's sides.\",\n",
       " 'This afforded each house a magnificent view of the harbor, but left no room for driveways, so people parked their cars on the curb in front of their house.',\n",
       " 'She guessed people in Colonial times had had little use of cars.\\n',\n",
       " 'At this time of night, the whole street was filled with parked cars, and her heart sank as she realized she would have to drive back up the hill and find a free spot far away from the house.',\n",
       " 'The prospect of walking just a few hundred yards on uneven Annapolis cobbles in wintry darkness in her condition was decidedly unpleasant.\\n',\n",
       " \"Then she saw that there was a big gap right in front of the house, as if a protective force field was projecting from the house itself, and realized that it shouldn't have surprised her.\",\n",
       " 'She remembered that it had been the same when she had been living at home.',\n",
       " 'It was almost like the gap that schooling fish leave around a reef shark--after a few years, all the neighbors along the south end of Market Street had known to steer clear of the angry old widow in the purple house.\\n',\n",
       " 'Protective force field or not',\n",
       " \", it was a welcome sight at this hour, and she easily parallel parked the car with plenty of space left for Chris's rental, whenever he would show up.\",\n",
       " 'Then she dragged a last time on her cigarette and half-heartedly blew smoke out the cracked window before closing it, turning off the ignition, and getting out of the car. \\n',\n",
       " \"Her first thought was how silent it was with the car's engine and radio off.\",\n",
       " 'Her second was that it was cold, much colder than mere temperature had suggested.',\n",
       " 'With one hand, she dragged her thick parka closed against the damp chill of the Chesapeake stealing into her bones, and with the other, she waved the remnants of the smoke out of the car and dropped the butt of the cigarette in the gutter.\\n',\n",
       " 'And froze.\\n',\n",
       " 'An elderly lady, diminutive but ramrod-straight figure embalmed in a downy parka that made her look twice her actual size, was staring at Kate from the curb.',\n",
       " 'A terrier, fur the color of midnight and encased in a coat of the same color and cut as his owner, was straining at his leash and looking back questioningly over his shoulder at his owner, who must have stopped dead in her tracks.',\n",
       " \"The yellow light shining down from the tired old lamppost above was feeble, but enough to reveal the old woman's horrified and disgusted look framed by the furlined hood. \\n\",\n",
       " 'Kate hurriedly took a step back into the shelter of the car, trying to shield her belly.',\n",
       " 'At close to seven months, it was a mostly futile gesture, and she knew it.\\n',\n",
       " '\"Smoking is bad for the baby, you know, young lady,\" the old lady said primly in a reedy voice that cut through the night unpleasantly.',\n",
       " '\"',\n",
       " \"And it's bad for you, too.\",\n",
       " '\"\\n',\n",
       " '\"I know, thank you,\" Kate said, feeling her cheeks start to burn like a school girl\\'s, and hating herself for it even if it was too dark for anyone to see it.',\n",
       " '\"',\n",
       " 'It was my friend\\'s cigarette, not mine,\" she continued lamely.\\n',\n",
       " '\"Hmmpf,\" the old lady said, putting her nose up.',\n",
       " '\"',\n",
       " 'Come on, Skippy, time to go.',\n",
       " '\"\\n',\n",
       " 'The terrier yapped eagerly in agreement, and then continued to pull his owner up the hill.',\n",
       " 'As the deadened footsteps faded away, Kate sighed in relief and leaned against the car, feeling the blush fading as her pulse stabilized again.',\n",
       " 'Intruding old bitch, she thought with heat that surprised herself.',\n",
       " 'You should mind your own business.',\n",
       " 'That made her feel a little better.\\n',\n",
       " \"On the plus side, she wasn't cold anymore.\",\n",
       " 'She took a moment to steady her breathing, then glanced up at the house above her.',\n",
       " 'As always, it loomed above her, a rickety wooden colossus of two stories and with a pointy tower rising another level.',\n",
       " 'Perched on the ridge lining Market Street, it looked like a gangly giant leaning over to grab her.\\n',\n",
       " 'She shivered involuntarily, feeling another wave of memories rising up in her gorge, and instead fished her phone out of her pocket to stave off the onslaught.\\n',\n",
       " \"Chris's text was written in his usual clipped and businesslike language.\",\n",
       " '\"',\n",
       " 'At gate.',\n",
       " 'Takeoff in thirty, weather willing.',\n",
       " 'Arrive Annapolis 10pm.',\n",
       " 'Call if U can.',\n",
       " '\"\\n',\n",
       " 'She tapped the call button and waited as she was connected, leaning against the car with snow falling peacefully all around her.',\n",
       " 'The memory of the condemning old lady was fading just as quickly as her footsteps were being carefully concealed by big woolly flakes.\\n',\n",
       " '\"',\n",
       " 'Hey you,\" Chris said.',\n",
       " 'He sounded tired.',\n",
       " '\"',\n",
       " 'You there yet?',\n",
       " '\"\\n',\n",
       " '\"Hey hon,\" she said.',\n",
       " '\"',\n",
       " 'Yep.',\n",
       " 'Just got here.',\n",
       " \"It's snowing here too, maybe even worse than in New York.\",\n",
       " '\"\\n',\n",
       " '\"How\\'s the baby?',\n",
       " '\"',\n",
       " 'he said.',\n",
       " '\"',\n",
       " 'And you?',\n",
       " 'How are you feeling?',\n",
       " '\"\\n',\n",
       " '\"Good,\" she lied.',\n",
       " '\"',\n",
       " 'Tired.',\n",
       " 'The baby is fine, too.',\n",
       " 'She says hi.',\n",
       " '\"\\n',\n",
       " 'He actually laughed at that.',\n",
       " '\"',\n",
       " \"Hey baby, daddy's on the way.\",\n",
       " 'Stay put and take care of mommy.',\n",
       " '\"\\n',\n",
       " 'She smiled, knowing he couldn\\'t see it. \"',\n",
       " \"Speaking of which, flight's still on for seven?\",\n",
       " '\"\\n',\n",
       " '\"Yes, they\\'re getting ready to board us now, so it\\'s looking pretty promising this time around.',\n",
       " '\"\\n',\n",
       " 'She nodded, grunted approvingly.',\n",
       " '\"',\n",
       " 'So what about you,',\n",
       " 'honey?',\n",
       " 'You',\n",
       " 'okay?',\n",
       " 'You sound a little tired.',\n",
       " '\"\\n',\n",
       " '\"The flight from Paris was a bitch,\" he admitted.',\n",
       " '\"',\n",
       " 'This return trip was not exactly planned to the nines.',\n",
       " '\"\\n',\n",
       " '\"',\n",
       " 'And the partners?',\n",
       " 'How are they taking this, on top of everything else?',\n",
       " '\"',\n",
       " \"She couldn't quite erase the uncertainty from her own voice, and hated herself for it.\",\n",
       " 'Top grades all through school, double Ivy league degrees, and now the youngest partner in history at Cumberland and McDonough, a top Manhattan law firm, and a woman to boot, but',\n",
       " \"she still felt like she was being sent to the principal's office whenever the partners--the other partners, which included Chris--were discussed.\\n\",\n",
       " '\"\\'Everything else\\', what\\'s that supposed to mean?',\n",
       " '\" he said sharply with that annoying lawyerly way he had.\\n',\n",
       " 'She grunted.',\n",
       " 'She guessed she had the same lawyerly way herself.',\n",
       " '\"',\n",
       " 'You know what,\" she said, and cupped her free hand around her belly.',\n",
       " \"Announcing her pregnancy at the partner's meeting last month--in fact, her first partner's meeting, period--had been something of a bomb shell, at least in her own mind, and she was sure they were all talking about her behind her back.\\n\",\n",
       " '\"',\n",
       " 'Yes, I guess I do know,\" he said, softening.',\n",
       " '\"',\n",
       " 'They understand, of course they understand.',\n",
       " '\"\\n',\n",
       " '\"I bet that old gargoyle McDonough has had plenty to say about it,\" she said darkly.',\n",
       " 'Chris had told her Melvin McDonough, one of the original founders of the firm, had been her most vocal opponent when the issue of her promotion had been discussed.',\n",
       " 'She was sure it was because she was a woman.',\n",
       " '\"',\n",
       " \"How he thought I was way past having babies, and how I'd turn into the mothering type, and all that crap.\",\n",
       " '\"\\n',\n",
       " 'He chuckled.',\n",
       " '\"',\n",
       " 'I bet, but not to my face.',\n",
       " \"Don't worry about it, there's nothing he can do to you now.\",\n",
       " '\"\\n',\n",
       " '\"I guess not,\" she muttered and stamped her feet.',\n",
       " 'She was getting cold again.\\n',\n",
       " '\"Wait, are you still outside in the snow?',\n",
       " '\" he said in mock outrage.',\n",
       " '\"',\n",
       " \"Let me guess, you're stalling from going into the house, so instead you're standing out there in the cold talking to me about law firm politics.\",\n",
       " '\"\\n',\n",
       " 'She snorted humorlessly.',\n",
       " '\"',\n",
       " 'Guilty as charged, counselor.',\n",
       " '\"\\n',\n",
       " 'He chuckled, and then suddenly grew serious.',\n",
       " '\"',\n",
       " 'Listen',\n",
       " ', I know this must be hard,\" he said.',\n",
       " '\"',\n",
       " \"Why don't you just find a coffee shop that's open late, or some cozy restaurant, and just hang out until I get there?\",\n",
       " '\"',\n",
       " 'His voice brightened as he got another idea.',\n",
       " '\"',\n",
       " 'Or why not just take into a hotel, we deal with this in the morning?',\n",
       " 'No way we want to stay in that spooky old house tonight anyway, am I right?',\n",
       " '\"\\n',\n",
       " 'She huffed.',\n",
       " '\"',\n",
       " 'I spent fifteen years of my life in that spooky old house, you know.',\n",
       " \"It's just a house.\",\n",
       " \"In fact, it's my house now.\",\n",
       " 'Mine and Jake\\'s and Matt\\'s house, that is,\" she corrected herself primly.\\n',\n",
       " 'He sighed audibly.',\n",
       " '\"',\n",
       " 'Fine,\" he said, sounding defeated.',\n",
       " \"She knew that he had never liked her family's old house on Market Street; in fact, had never much liked her family at all.\",\n",
       " 'Except her brothers, who were both likable enough, even if she privately felt they were pretty forgettable as well.',\n",
       " '\"',\n",
       " \"I'll see you around ten.\",\n",
       " 'Hey, I gotta go',\n",
       " \", looks like they're starting to board now.\",\n",
       " 'Love you.',\n",
       " '\"\\n',\n",
       " '\"Love you,\" she responded automatically, and then felt a twinge of unease as he hung up.',\n",
       " 'She let the phone fall from her ear as she turned over the phrase in her head, absently staring at the screen glowing like a precious jewel in the dim night.\\n',\n",
       " 'Together for twelve years, and married for ten, all loving and stable throughout that whole time.',\n",
       " 'Now since being hit with a surprise pregnancy only seven months ago, a lot of things she had been taking for granted were starting to no longer be true.',\n",
       " 'Like her love for Chris. \\n',\n",
       " 'Why was she feeling this way?',\n",
       " \"Wasn't pregnant couples supposed to grow stronger in their relationship, not weaker?\",\n",
       " 'And who would ever consider divorcing her husband of ten years, as a little voice kept whispering to her late at night, just when they finally had managed to conceive after all the medical options had failed?\\n',\n",
       " \"My mother, she thought bitterly, that's who.\",\n",
       " 'Her mother, who had forced a divorce on her poor father when she was six months pregnant with Kate herself.',\n",
       " 'Her father, who had died, certainly of a fatal fall from a ladder, and perhaps of grief from being estranged from his daughter only a month before she was born.\\n',\n",
       " \"Actually, it wasn't that she didn't love Chris anymore.\",\n",
       " 'She did, she loved him dearly in that familiar and comfortable way that established couples do, where most of the thrill has worn away but what remains is a deep friendship and a fundamental understanding for each other.',\n",
       " \"It was more of an impending feeling of doom that had been growing on her, like that little voice that kept telling her that she couldn't stay with him, that it somehow--impossibly--\",\n",
       " \"wouldn't be safe.\",\n",
       " \"As if he and the baby wouldn't be good together, even if she knew perfectly well that Chris would make a wonderful father.\",\n",
       " \"She couldn't quite put her feelings into words, but she felt it at the core of her being so strongly that she surreptitiously had started to look up divorce attorneys.\\n\",\n",
       " 'Enough.',\n",
       " 'She shook her head.',\n",
       " 'Chris was right, she was stalling.',\n",
       " 'This was a problem for another day.',\n",
       " 'With an effort, she lifted her gaze from her phone screen, now beaded with little droplets of melting snow, to look at the dark house looming over her beyond a veil of swirling flurries.',\n",
       " 'With its dark windows and gap-toothed front porch, it felt like it was leering at her.\\n',\n",
       " 'The problem at hand was her mom, she reminded herself.',\n",
       " 'Her mom, who was now dead.',\n",
       " 'And it was time to take care of the mess she had left behind.\\n',\n",
       " '#\\n',\n",
       " '\"',\n",
       " 'Hi mom,\" she had said lamely when her mother had answered on the second ring.\\n',\n",
       " 'That had only been a week ago, and her mother had sounded her usual cold and detached self.',\n",
       " \"Kate knew her mother didn't have a cellphone, and had been anticipating a long wait until the older woman had made it to her rotary phone in the parlor.\",\n",
       " 'Clearly she had either been sitting by the old Bakelite monstrosity, or had had no difficulties getting to it quickly.\\n',\n",
       " '\"',\n",
       " 'Well, well,\" the crisp voice, with just a hint of an old-person quake, came back through Kate\\'s phone.',\n",
       " '\"',\n",
       " \"If it isn't the long-lost daughter.\",\n",
       " 'Hello, dear, nice of you to take some time out of your important life to talk to your old mother.',\n",
       " '\"\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_by_paragraphs(txt, max_para = 1):\n",
    "    limits = []\n",
    "    for i, m in enumerate(re.finditer('\\n\\n', txt)):\n",
    "#         print(i)\n",
    "        if i>0 and i%max_para==0:  # consider 10 paras as single entity\n",
    "            limits.append(m.start())\n",
    "    limits.append(len(txt))\n",
    "    \n",
    "    return limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_entity(ent):\n",
    "    res = \"\"\n",
    "    for e in ent.ents:\n",
    "        if e.label_ == \"PERSON\":\n",
    "            res = res + e.text + \" \"\n",
    "    return res.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delimiter(txt, doc, gran=\"sent\"):\n",
    "    '''\n",
    "    # returns mapping for each token start index to unit index based on granualrity \n",
    "    # There are 3 possible values for granularity namely, para - paragraph, sent - sentence, CHAPTER - chapter\n",
    "    '''\n",
    "    limits = None\n",
    "    if gran==\"para\":\n",
    "        limits = [m.start() for m in re.finditer('\\n\\n', txt)]\n",
    "    elif gran==\"sent\":\n",
    "        limits = [sent.start_char for sent in doc.sents][1:]\n",
    "    elif gran==\"CHAPTER\":\n",
    "        limits = [m.start() for m in re.finditer(gran, txt)]\n",
    "    \n",
    "    # print(limits)\n",
    "    # mapping a start ind of each token to granularity index\n",
    "    res = {}\n",
    "    limit_ind = 0\n",
    "    for e in doc:\n",
    "        if limit_ind<len(limits) and e.idx>limits[limit_ind]:\n",
    "            limit_ind += 1\n",
    "        res[e.idx] = limit_ind\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_by_paragraphs(paragraph,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16495]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 0\n",
    "docs = []\n",
    "sent_i = 0\n",
    "entities = {}\n",
    "res = []\n",
    "mapping = []\n",
    "sent = 0\n",
    "for end in splits:\n",
    "#     print(\"##########\")\n",
    "#     print(paragraph[st:end])\n",
    "    doc = nlp(paragraph[st:end])\n",
    "    mapping = [sent.start_char+st for sent in doc.sents]\n",
    "    for c in doc._.coref_clusters:\n",
    "        # we only consider proper nouns like 'ALICE'\n",
    "        main_ent = extract_main_entity(c.main)\n",
    "        if len(main_ent)>0:\n",
    "#             print(main_ent)\n",
    "            for ent in c.mentions:\n",
    "#                 res.append((main_ent, st + ent.start_char))\n",
    "#                 print(ent.start_char)\n",
    "                for i in range(len(mapping)):\n",
    "                    m = mapping[i]\n",
    "                    if ent.start_char+st > m:\n",
    "                        sent = i+sent_i\n",
    "                res.append({\"name\":main_ent, \"sentence\":sent})\n",
    "\n",
    "    sent_i += len(mapping)\n",
    "    st = end + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Harry Potter has been spending another unhappy summer with the Dursleys. When Aunt Marge Dursley insults his parents, he loses his temper and accidentally causes her to inflate like a balloon and float away. Fed up, Harry then flees the Dursleys with his broom and trunk. The Knight Bus arrives and takes Harry to the Leaky Cauldron, where he is pardoned by Minister for Magic Cornelius Fudge for using magic outside of Hogwarts. After reuniting with his best friends Ron Weasley and Hermione Granger, Harry learns that Sirius Black, a convicted supporter of the dark wizard Lord Voldemort, has escaped Azkaban prison and intends to kill him.\n",
      "\n",
      "The trio return to Hogwarts for the school year on the Hogwarts Express train, which is suddenly boarded by dementors, ghostly prison guards that are searching for Black. One enters the trio's compartment, causing Harry to pass out, but new Defence Against the Dark Arts teacher Remus Lupin repels the dementor with a Patronus Charm. At Hogwarts, headmaster Albus Dumbledore announces that dementors will be guarding the school until Black is captured. Hogwarts groundskeeper Rubeus Hagrid is announced as the new Care of Magical Creatures teacher; his first class goes badly when Draco Malfoy deliberately provokes the hippogriff Buckbeak, who then attacks him. Draco exaggerates his injury, and his father Lucius Malfoy later has Buckbeak sentenced to death.\n",
      "************\n",
      "Harry Potter has been spending another unhappy summer with the Dursleys.\n",
      "Harry Potter 0\n",
      "Dursleys 0\n",
      "************\n",
      "When Aunt Marge Dursley insults Harry Potter parents, Harry Potter loses Harry Potter temper and accidentally causes Aunt Marge Dursley to inflate like a balloon and float away.\n",
      "Aunt Marge Dursley 1\n",
      "Harry Potter 1\n",
      "Harry Potter 1\n",
      "Harry Potter 1\n",
      "Aunt Marge Dursley 1\n",
      "************\n",
      "Fed up, Harry then flees the Dursleys with Harry broom and trunk.\n",
      "Harry 2\n",
      "Dursleys 2\n",
      "Harry 2\n",
      "************\n",
      "The Knight Bus arrives and takes Harry to the Leaky Cauldron, where Harry is pardoned by Minister for Magic Cornelius Fudge for using magic outside of Hogwarts.\n",
      "Harry 3\n",
      "Harry 3\n",
      "Cornelius Fudge 3\n",
      "************\n",
      "After reuniting with his best friends Ron Weasley and Hermione Granger, Harry learns that Sirius Black, a convicted supporter of the dark wizard Lord Voldemort, has escaped Azkaban prison and intends to kill Azkaban prison.\n",
      "\n",
      "\n",
      "Ron Weasley 4\n",
      "Hermione Granger 4\n",
      "Harry 4\n",
      "Voldemort 4\n",
      "************\n",
      "Sirius Black, a convicted supporter of the dark wizard Lord Voldemort, has escaped Azkaban prison and intends to kill him return to Hogwarts for the school year on the Hogwarts Express train, which is suddenly boarded by dementors, ghostly prison guards that are searching for Black.\n",
      "Voldemort 5\n",
      "************\n",
      "One enters the trio's compartment, causing Harry to pass out, but new Defence Against the Dark Arts teacher Remus Lupin repels the dementor with a Patronus Charm.\n",
      "Harry 6\n",
      "Remus Lupin 6\n",
      "************\n",
      "At Hogwarts, headmaster Albus Dumbledore announces that dementors will be guarding the school until Black is captured.\n",
      "Albus Dumbledore 7\n",
      "Black 7\n",
      "************\n",
      "Hogwarts groundskeeper Rubeus Hagrid is announced as the new Care of Magical Creatures teacher; Hogwarts groundskeeper Rubeus Hagrid first class goes badly when Draco Malfoy deliberately provokes the hippogriff\n",
      "Rubeus Hagrid 8\n",
      "Rubeus Hagrid 8\n",
      "Draco Malfoy 8\n",
      "************\n",
      "Buckbeak, who then attacks Draco Malfoy.\n",
      "Buckbeak 9\n",
      "Draco Malfoy 9\n",
      "************\n",
      "Draco Malfoy exaggerates Draco Malfoy injury, and Draco Malfoy father Lucius Malfoy later has Buckbeak sentenced to death.\n",
      "Draco Malfoy 10\n",
      "Draco Malfoy 10\n",
      "Draco Malfoy 10\n",
      "Lucius Malfoy 10\n",
      "Buckbeak 10\n",
      "##########\n",
      "\n",
      "\n",
      "The Fat Lady's portrait, which guards the Gryffindor rooms, is found ruined and empty. Terrified and hiding in another painting, she tells Dumbledore that Black has entered the castle. During a stormy Quidditch match against Hufflepuff, dementors attack Harry, causing him to fall off his broomstick which lands at the Whomping Willow, where it is destroyed. At Hogsmeade, Harry is shocked to learn that not only had Sirius been his father's best friend and apparently betrayed them to Voldemort, but is also Harry's godfather. Lupin privately teaches Harry to defend himself against dementors using the Patronus Charm.\n",
      "************\n",
      "\n",
      "\n",
      "The Fat Lady's portrait, which guards the Gryffindor rooms, is found ruined and empty.\n",
      "************\n",
      "Terrified and hiding in another painting, \n",
      "\n",
      "The Fat Lady tells Dumbledore that Black has entered the castle.\n",
      "Black 12\n",
      "************\n",
      "During a stormy Quidditch match against Hufflepuff, dementors attack Harry, causing Harry to fall off Harry broomstick which lands at the Whomping Willow, where it is destroyed.\n",
      "Harry 13\n",
      "Harry 13\n",
      "Harry 13\n",
      "************\n",
      "At Hogsmeade, Harry is shocked to learn that not only had Sirius been Harry father's best friend and apparently betrayed them to Voldemort, but is also Harry's godfather.\n",
      "Harry 14\n",
      "Sirius 14\n",
      "Harry 14\n",
      "Voldemort 14\n",
      "Harry 14\n",
      "************\n",
      "Lupin privately teaches Harry to defend Harry against dementors using the Patronus Charm.\n",
      "Lupin 15\n",
      "Harry 15\n",
      "Harry 15\n",
      "##########\n",
      "\n",
      "\n",
      "After Harry, Ron, and Hermione witness Buckbeak's apparent execution, Ron's pet rat Scabbers bites him and escapes. When Ron gives chase, a large dog appears and drags both Ron and Scabbers into a hole at the Whomping Willow's base. This leads the trio to an underground passage to the Shrieking Shack, where they discover that the dog is actually Sirius, who is an Animagus. Lupin arrives and embraces Sirius as an old friend. He admits to being a werewolf, and explains that Sirius is innocent. Sirius was falsely accused of betraying the Potters to Voldemort, as well as murdering twelve Muggles and their mutual friend, Peter Pettigrew. It is revealed that Scabbers is actually Pettigrew, an Animagus who betrayed the Potters and committed the murders.\n",
      "************\n",
      "\n",
      "\n",
      "After Harry, Ron, and Hermione witness Buckbeak's apparent execution, Ron's pet rat Scabbers bites Ron and escapes.\n",
      "Harry 16\n",
      "Ron 16\n",
      "Hermione 16\n",
      "Buckbeak 16\n",
      "Ron 16\n",
      "Scabbers 16\n",
      "Ron 16\n",
      "************\n",
      "When Ron gives chase, a large dog appears and drags both Ron and Scabbers into a hole at the Whomping Willow's base.\n",
      "Ron 17\n",
      "Ron 17\n",
      "Scabbers 17\n",
      "************\n",
      "This leads the trio to an underground passage to the Shrieking Shack, where the trio discover that a large dog is actually Sirius, who is an Animagus.\n",
      "************\n",
      "Lupin arrives and embraces Sirius as an old friend.\n",
      "Lupin 19\n",
      "************\n",
      "Lupin admits to being a werewolf, and explains that Sirius is innocent.\n",
      "Lupin 20\n",
      "************\n",
      "Sirius was falsely accused of betraying the Potters to Voldemort, as well as murdering twelve Muggles and the Potters mutual friend, Peter Pettigrew.\n",
      "Voldemort 21\n",
      "Peter Pettigrew 21\n",
      "************\n",
      "It is revealed that Scabbers is actually Pettigrew, an Animagus who betrayed the Potters and committed the murders.\n",
      "Scabbers 22\n",
      "Pettigrew 22\n",
      "Animagus 22\n",
      "##########\n",
      "\n",
      "\n",
      "Severus Snape arrives to apprehend Black but Harry knocks him unconscious with the Expelliarmus spell. After forcing Pettigrew back into human form, Lupin and Sirius prepare to kill him, but Harry convinces them to turn Pettigrew over to the dementors.\n",
      "************\n",
      "\n",
      "\n",
      "Severus Snape arrives to apprehend Black but\n",
      "Severus Snape 23\n",
      "Black 23\n",
      "************\n",
      "Harry knocks \n",
      "\n",
      "Severus Snape unconscious with the Expelliarmus spell.\n",
      "Harry 24\n",
      "Expelliarmus 24\n",
      "************\n",
      "After forcing Pettigrew back into human form, Lupin and Sirius prepare to kill Pettigrew, but Harry convinces Lupin and Sirius to turn Pettigrew over to the dementors.\n",
      "Pettigrew 25\n",
      "Lupin 25\n",
      "Pettigrew 25\n",
      "Harry 25\n",
      "Lupin 25\n",
      "Pettigrew 25\n",
      "##########\n",
      "\n",
      "\n",
      "As the group departs, the full moon rises and Lupin transforms into a werewolf. Sirius transforms into his dog form to fight him off. In the midst of the chaos, Pettigrew transforms back into a rat and escapes. Harry and Sirius are attacked by dementors, and Harry sees a figure in the distance save them by casting a powerful Patronus spell. He believes the mysterious figure is his deceased father before passing out. He awakens to discover that Sirius has been captured and sentenced to the Dementor's Kiss.\n",
      "************\n",
      "\n",
      "\n",
      "As the group departs, the full moon rises and Lupin transforms into a werewolf.\n",
      "Lupin 26\n",
      "************\n",
      "Sirius transforms into his dog form to fight his off.\n",
      "************\n",
      "In the midst of the chaos, Pettigrew transforms back into a rat and escapes.\n",
      "Pettigrew 28\n",
      "************\n",
      "Harry and Sirius are attacked by dementors, and Harry sees a figure in the distance save Harry and Sirius by casting a powerful Patronus spell.\n",
      "Harry 29\n",
      "Sirius 29\n",
      "Harry 29\n",
      "Harry 29\n",
      "Sirius 29\n",
      "************\n",
      "Harry believes a figure is Harry deceased father before passing out.\n",
      "Harry 30\n",
      "Harry 30\n",
      "************\n",
      "Harry awakens to discover that Sirius has been captured and sentenced to the Dementor's Kiss.\n",
      "Harry 31\n",
      "##########\n",
      "\n",
      "\n",
      "Acting on Dumbledore's advice, Harry and Hermione travel back in time using Hermione's Time Turner, and watch themselves and Ron repeat the night's events. They save Buckbeak from execution and witness the Dementors overpower Harry and Sirius. The present Harry realises that it was actually himself who conjured the Patronus, and does so again. Harry and Hermione rescue Sirius, who escapes with Buckbeak. Exposed as a werewolf, Lupin resigns from teaching to prevent an uproar from parents. He also returns the Marauder's Map to Harry, as he no longer has the authority to confiscate contraband. Sirius sends Harry a Firebolt broom, and he happily takes it for a ride.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "\n",
      "\n",
      "Acting on Dumbledore's advice, Harry and Hermione travel back in time using Hermione's Time Turner, and watch Harry and Hermione and Ron repeat the night's events.\n",
      "Dumbledore 32\n",
      "Harry 32\n",
      "Hermione 32\n",
      "Hermione 32\n",
      "Time Turner 32\n",
      "Harry 32\n",
      "Hermione 32\n",
      "Ron 32\n",
      "************\n",
      "Harry and Hermione save Buckbeak from execution and witness the Dementors overpower Harry and Sirius.\n",
      "Harry 33\n",
      "Hermione 33\n",
      "Buckbeak 33\n",
      "Dementors 33\n",
      "Harry 33\n",
      "Sirius 33\n",
      "************\n",
      "Harry Harry realises that it was actually Harry who conjured the Patronus, and does so again.\n",
      "Harry Harry 34\n",
      "Harry 34\n",
      "************\n",
      "Harry and Hermione rescue Sirius, who escapes with Buckbeak.\n",
      "Harry 35\n",
      "Hermione 35\n",
      "Sirius 35\n",
      "Buckbeak 35\n",
      "************\n",
      "Exposed as a werewolf, Lupin resigns from teaching to prevent an uproar from parents.\n",
      "Lupin 36\n",
      "************\n",
      "Lupin also returns the Marauder's Map to Harry, as Lupin no longer has the authority to confiscate contraband.\n",
      "Lupin 37\n",
      "Harry 37\n",
      "************\n",
      "Sirius sends Harry a Firebolt broom, and Lupin happily takes a Firebolt broom for a ride.\n",
      "Harry a Firebolt 38\n",
      "Lupin 38\n"
     ]
    }
   ],
   "source": [
    "st = 0\n",
    "docs = []\n",
    "sent_i = 0\n",
    "entities = {}\n",
    "res = []\n",
    "mapping = []\n",
    "for end in splits:\n",
    "#     print(\"##########\")\n",
    "#     print(paragraph[st:end])\n",
    "    doc = nlp(paragraph[st:end])\n",
    "    new_txt = doc._.coref_resolved\n",
    "    new_doc = nlp(new_txt)\n",
    "    docs.append(new_doc)\n",
    "    mapping.extend([sent.start_char+st for sent in doc.sents])\n",
    "    for i, sent in enumerate(new_doc.sents):\n",
    "        print(\"************\")\n",
    "        print(sent)\n",
    "        for ent in sent.ents:\n",
    "            ent_txt = ent.text.strip().replace(\"'d\",\"\").replace(\".\",\"\")\n",
    "            if (ent.label_ == \"PERSON\"):\n",
    "                print(ent_txt, sent_i)\n",
    "                res.append({\"name\":ent_txt, \"sentence\":sent_i})\n",
    "                entities[ent_txt] = 1\n",
    "        sent_i += 1\n",
    "    st = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Harry Potter', 'sentence': 0},\n",
       " {'name': 'Dursleys', 'sentence': 0},\n",
       " {'name': 'Aunt Marge Dursley', 'sentence': 1},\n",
       " {'name': 'Harry Potter', 'sentence': 1},\n",
       " {'name': 'Harry Potter', 'sentence': 1},\n",
       " {'name': 'Harry Potter', 'sentence': 1},\n",
       " {'name': 'Aunt Marge Dursley', 'sentence': 1},\n",
       " {'name': 'Harry', 'sentence': 2},\n",
       " {'name': 'Dursleys', 'sentence': 2},\n",
       " {'name': 'Harry', 'sentence': 2},\n",
       " {'name': 'Harry', 'sentence': 3},\n",
       " {'name': 'Harry', 'sentence': 3},\n",
       " {'name': 'Cornelius Fudge', 'sentence': 3},\n",
       " {'name': 'Ron Weasley', 'sentence': 4},\n",
       " {'name': 'Hermione Granger', 'sentence': 4},\n",
       " {'name': 'Harry', 'sentence': 4},\n",
       " {'name': 'Voldemort', 'sentence': 4},\n",
       " {'name': 'Voldemort', 'sentence': 5},\n",
       " {'name': 'Harry', 'sentence': 6},\n",
       " {'name': 'Remus Lupin', 'sentence': 6},\n",
       " {'name': 'Albus Dumbledore', 'sentence': 7},\n",
       " {'name': 'Black', 'sentence': 7},\n",
       " {'name': 'Rubeus Hagrid', 'sentence': 8},\n",
       " {'name': 'Rubeus Hagrid', 'sentence': 8},\n",
       " {'name': 'Draco Malfoy', 'sentence': 8},\n",
       " {'name': 'Buckbeak', 'sentence': 9},\n",
       " {'name': 'Draco Malfoy', 'sentence': 9},\n",
       " {'name': 'Draco Malfoy', 'sentence': 10},\n",
       " {'name': 'Draco Malfoy', 'sentence': 10},\n",
       " {'name': 'Draco Malfoy', 'sentence': 10},\n",
       " {'name': 'Lucius Malfoy', 'sentence': 10},\n",
       " {'name': 'Buckbeak', 'sentence': 10},\n",
       " {'name': 'Black', 'sentence': 13},\n",
       " {'name': 'Harry', 'sentence': 14},\n",
       " {'name': 'Harry', 'sentence': 14},\n",
       " {'name': 'Harry', 'sentence': 14},\n",
       " {'name': 'Harry', 'sentence': 15},\n",
       " {'name': 'Sirius', 'sentence': 15},\n",
       " {'name': 'Harry', 'sentence': 15},\n",
       " {'name': 'Voldemort', 'sentence': 15},\n",
       " {'name': 'Harry', 'sentence': 15},\n",
       " {'name': 'Lupin', 'sentence': 16},\n",
       " {'name': 'Harry', 'sentence': 16},\n",
       " {'name': 'Harry', 'sentence': 16},\n",
       " {'name': 'Harry', 'sentence': 17},\n",
       " {'name': 'Ron', 'sentence': 17},\n",
       " {'name': 'Hermione', 'sentence': 17},\n",
       " {'name': 'Buckbeak', 'sentence': 17},\n",
       " {'name': 'Ron', 'sentence': 17},\n",
       " {'name': 'Scabbers', 'sentence': 17},\n",
       " {'name': 'Ron', 'sentence': 17},\n",
       " {'name': 'Ron', 'sentence': 18},\n",
       " {'name': 'Ron', 'sentence': 18},\n",
       " {'name': 'Scabbers', 'sentence': 18},\n",
       " {'name': 'Lupin', 'sentence': 20},\n",
       " {'name': 'Lupin', 'sentence': 21},\n",
       " {'name': 'Voldemort', 'sentence': 22},\n",
       " {'name': 'Peter Pettigrew', 'sentence': 22},\n",
       " {'name': 'Scabbers', 'sentence': 23},\n",
       " {'name': 'Pettigrew', 'sentence': 23},\n",
       " {'name': 'Animagus', 'sentence': 23},\n",
       " {'name': 'Severus Snape', 'sentence': 24},\n",
       " {'name': 'Black', 'sentence': 24},\n",
       " {'name': 'Harry', 'sentence': 25},\n",
       " {'name': 'Expelliarmus', 'sentence': 25},\n",
       " {'name': 'Pettigrew', 'sentence': 26},\n",
       " {'name': 'Lupin', 'sentence': 26},\n",
       " {'name': 'Pettigrew', 'sentence': 26},\n",
       " {'name': 'Harry', 'sentence': 26},\n",
       " {'name': 'Lupin', 'sentence': 26},\n",
       " {'name': 'Pettigrew', 'sentence': 26},\n",
       " {'name': 'Lupin', 'sentence': 27},\n",
       " {'name': 'Pettigrew', 'sentence': 29},\n",
       " {'name': 'Harry', 'sentence': 30},\n",
       " {'name': 'Sirius', 'sentence': 30},\n",
       " {'name': 'Harry', 'sentence': 30},\n",
       " {'name': 'Harry', 'sentence': 30},\n",
       " {'name': 'Sirius', 'sentence': 30},\n",
       " {'name': 'Harry', 'sentence': 31},\n",
       " {'name': 'Harry', 'sentence': 31},\n",
       " {'name': 'Harry', 'sentence': 32},\n",
       " {'name': 'Dumbledore', 'sentence': 33},\n",
       " {'name': 'Harry', 'sentence': 33},\n",
       " {'name': 'Hermione', 'sentence': 33},\n",
       " {'name': 'Hermione', 'sentence': 33},\n",
       " {'name': 'Time Turner', 'sentence': 33},\n",
       " {'name': 'Harry', 'sentence': 33},\n",
       " {'name': 'Hermione', 'sentence': 33},\n",
       " {'name': 'Ron', 'sentence': 33},\n",
       " {'name': 'Harry', 'sentence': 34},\n",
       " {'name': 'Hermione', 'sentence': 34},\n",
       " {'name': 'Buckbeak', 'sentence': 34},\n",
       " {'name': 'Dementors', 'sentence': 34},\n",
       " {'name': 'Harry', 'sentence': 34},\n",
       " {'name': 'Sirius', 'sentence': 34},\n",
       " {'name': 'Harry Harry', 'sentence': 35},\n",
       " {'name': 'Harry', 'sentence': 35},\n",
       " {'name': 'Harry', 'sentence': 36},\n",
       " {'name': 'Hermione', 'sentence': 36},\n",
       " {'name': 'Sirius', 'sentence': 36},\n",
       " {'name': 'Buckbeak', 'sentence': 36},\n",
       " {'name': 'Lupin', 'sentence': 37},\n",
       " {'name': 'Lupin', 'sentence': 38},\n",
       " {'name': 'Harry', 'sentence': 38},\n",
       " {'name': 'Harry a Firebolt', 'sentence': 39},\n",
       " {'name': 'Lupin', 'sentence': 39}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_i = 0\n",
    "# for doc in docs:\n",
    "#     for i, sent in enumerate(doc.sents):\n",
    "#         print(sent.text)\n",
    "#         for ent in entities:\n",
    "#             if(ent in sent.text):\n",
    "#                 res.append({\"name\":ent, \"sentence\":sent_i})\n",
    "                \n",
    "#         sent_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = 0\n",
    "# docs = []\n",
    "# sent_i = 0\n",
    "# entities = {}\n",
    "# res = {}\n",
    "# mapping = []\n",
    "# for end in splits:\n",
    "#     doc = nlp(paragraph[st:end])\n",
    "#     mapping.extend([sent.start_char+st for sent in doc.sents])\n",
    "#     for c in doc._.coref_clusters:\n",
    "#         # we only consider proper nouns like 'ALICE'\n",
    "#         main_ent = extract_main_entity(c.main)\n",
    "\n",
    "#         if len(main_ent)>0:\n",
    "#             if main_ent not in res:\n",
    "#                 res[main_ent] = []\n",
    "#             #print(str(main_entity), len(c.mentions))\n",
    "#             for ent in c.mentions:\n",
    "#                 #res.append((main_ent, st + ent.start_char))\n",
    "#                 res[main_ent].append((main_ent, st + ent.start_char, st + ent.end_char, ent))\n",
    "#     st = end + 1\n",
    "    \n",
    "#     r = []\n",
    "#     for k in res:\n",
    "#         r.extend(res[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline for long doucments\n",
    "# given some text and level of granularity, returns list of entities along with their index\n",
    "# def timeline(txt):\n",
    "    \n",
    "\n",
    "#     st = 0\n",
    "#     res = {}\n",
    "#     for end in limits:\n",
    "#         doc = nlp(txt[st:end])\n",
    "#         for c in doc._.coref_clusters:\n",
    "#             # we only consider proper nouns like 'ALICE'\n",
    "#             main_ent = extract_main_entity(c.main)\n",
    "                \n",
    "#             if len(main_ent)>0:\n",
    "#                 if main_ent not in res:\n",
    "#                     res[main_ent] = []\n",
    "#                 #print(str(main_entity), len(c.mentions))\n",
    "#                 for ent in c.mentions:\n",
    "#                     #res.append((main_ent, st + ent.start_char))\n",
    "#                     res[main_ent].append((main_ent, st + ent.start_char, st + ent.end_char, ent))\n",
    "#         st = end + 1\n",
    "    \n",
    "#     r = []\n",
    "#     for k in res:\n",
    "#         r.extend(res[k])\n",
    "    \n",
    "#     return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraph = \"Natalie, wait for me, screamed Adam. I have no time now, said Natalie. I will meet you in the evening, with Gabe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(paragraph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_text = doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(resolved_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ref = {'Harry':'Harry', 'Harry Potter':'Harry', \n",
    "                'Hermione': 'Hermione', 'Lupin': 'Lupin',\n",
    "               'Sirius':'Sirius'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = char_ref.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Harry', 'Harry Potter', 'Hermione', 'Lupin', 'Sirius'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_entity(text, char_ref):\n",
    "    for k in char_ref:\n",
    "        if text in k:\n",
    "            return k\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "Harry Potter spend\n",
      "429\n",
      "429\n",
      "Harry Potter lose\n",
      "429\n",
      "429\n",
      "Harry flee\n",
      "429\n",
      "429\n",
      "Harry learn\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "Harry pass\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "Harry fall\n",
      "429\n",
      "429\n",
      "Harry be\n",
      "429\n",
      "Sirius be\n",
      "429\n",
      "Lupin teach\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "Lupin arrive\n",
      "429\n",
      "Lupin admit\n",
      "429\n",
      "Sirius be\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "Harry knock\n",
      "429\n",
      "Lupin prepare\n",
      "429\n",
      "Harry convince\n",
      "429\n",
      "429\n",
      "Lupin transform\n",
      "429\n",
      "Sirius transform\n",
      "429\n",
      "429\n",
      "Harry see\n",
      "429\n",
      "Harry believe\n",
      "429\n",
      "429\n",
      "Harry awaken\n",
      "429\n",
      "Harry travel\n",
      "429\n",
      "Harry repeat\n",
      "429\n",
      "Harry save\n",
      "429\n",
      "429\n",
      "Harry realise\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "Lupin resign\n",
      "429\n",
      "Lupin return\n",
      "429\n",
      "Lupin have\n",
      "429\n",
      "Sirius send\n",
      "429\n",
      "Lupin take\n"
     ]
    }
   ],
   "source": [
    "for token in new_doc:\n",
    "    if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "        print(token.dep)\n",
    "        main_ent = extract_main_entity(token.text)\n",
    "        if token.text in char_ref:\n",
    "            print(token.text,token.head.lemma_)\n",
    "        elif main_ent:\n",
    "            print(main_ent,token.head.lemma_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter Potter nsubj spending VERB spend\n",
      "Harry Potter Potter nsubj loses VERB lose\n",
      "Harry Harry nsubj flees VERB flee\n",
      "Harry Harry nsubj learns VERB learn\n",
      "Harry Harry nsubj pass VERB pass\n",
      "Harry Harry nsubj fall VERB fall\n",
      "Harry Harry nsubj is VERB be\n",
      "Sirius Sirius nsubj been VERB be\n",
      "Lupin Lupin nsubj teaches VERB teach\n",
      "Lupin Lupin nsubj arrives VERB arrive\n",
      "Lupin Lupin nsubj admits VERB admit\n",
      "Sirius Sirius nsubj is VERB be\n",
      "Harry Harry nsubj knocks VERB knock\n",
      "Lupin Lupin nsubj prepare VERB prepare\n",
      "Harry Harry nsubj convinces VERB convince\n",
      "Lupin Lupin nsubj transforms VERB transform\n",
      "Sirius Sirius nsubj transforms VERB transform\n",
      "Harry Harry nsubj sees VERB see\n",
      "Harry Harry nsubj believes VERB believe\n",
      "Harry Harry nsubj awakens VERB awaken\n",
      "Harry Harry nsubj travel VERB travel\n",
      "Harry Harry nsubj repeat VERB repeat\n",
      "Harry Harry nsubj save VERB save\n",
      "Lupin Lupin nsubj resigns VERB resign\n",
      "Lupin Lupin nsubj returns VERB return\n",
      "Lupin Lupin nsubj has VERB have\n",
      "Sirius Sirius nsubj sends VERB send\n",
      "Lupin Lupin nsubj takes VERB take\n"
     ]
    }
   ],
   "source": [
    "for chunk in new_doc.noun_chunks:\n",
    "    if chunk.text in char_ref:\n",
    "        main_ent = extract_main_entity:\n",
    "        if chunk.root.dep_ == \"nsubj\" and chunk.root.head.pos_ == \"VERB\":\n",
    "            print(chunk.text,chunk.root.head.lemma_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns mapping for each token start index to unit index based on granualrity \n",
    "# There are 3 possible values for granularity namely, para - paragraph, sent - sentence, CHAPTER - chapter\n",
    "def delimiter(txt, doc, gran=\"para\"):\n",
    "    limits = None\n",
    "    if gran==\"para\":\n",
    "        limits = [m.start() for m in re.finditer('\\n\\n', txt)]\n",
    "    elif gran==\"sent\":\n",
    "        limits = [sent.start_char for sent in doc.sents]\n",
    "    elif gran==\"CHAPTER\":\n",
    "        limits = [m.start() for m in re.finditer(gran, txt)]\n",
    "    # mapping a start ind of each token to granularity index\n",
    "    res = {}\n",
    "    limit_ind = 0\n",
    "    for e in doc:\n",
    "        if limit_ind<len(limits) and e.idx>limits[limit_ind]:\n",
    "            limit_ind += 1\n",
    "        res[e.idx] = limit_ind\n",
    "    return res\n",
    "    \n",
    "# # given some text and level of granularity, returns list of entities along with their index\n",
    "# def timeline(txt, gran=\"para\"):\n",
    "#     new_txt = nlp(txt)._.coref_resolved\n",
    "#     doc = nlp(new_txt)\n",
    "#     mapping = delimiter(txt, doc, gran)\n",
    "#     res = []\n",
    "#     for ent in doc.ents:\n",
    "# #         main_entity = c.main[-1]\n",
    "# #         print(c)\n",
    "#         # we only consider proper nouns like 'ALICE'\n",
    "#         ent_txt = ent.text.strip()\n",
    "#         if (ent.label_ == \"PERSON\"):\n",
    "#             res.append({\"name\":ent_txt, \"sentence\":mapping[ent.start_char]})\n",
    "#     return res\n",
    "\n",
    "# given some text and level of granularity, returns list of entities along with their index\n",
    "def timeline(txt, gran=\"para\"):\n",
    "    doc = nlp(txt)\n",
    "    mapping = delimiter(txt, doc, gran)\n",
    "    res = []\n",
    "    for c in doc._.coref_clusters:\n",
    "        main_entity = c.main[-1]\n",
    "#         print(main_entity.text, main_entity.pos_)\n",
    "        # we only consider proper nouns like 'ALICE'\n",
    "        if main_entity.pos_ == \"PROPN\":\n",
    "            #print(str(main_entity), len(c.mentions))\n",
    "            for ent in c.mentions:\n",
    "                res.append((main_entity.text, mapping[ent.start_char]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given some text and level of granularity, returns list of entities along with their index\n",
    "def timeline(txt, gran=\"para\"):\n",
    "    doc = nlp(txt)\n",
    "    mapping = delimiter(txt, doc, gran)\n",
    "    res = []\n",
    "    for c in doc._.coref_clusters:\n",
    "        # we only consider proper nouns like 'ALICE'\n",
    "        main_ent = extract_main_entity(c.main)\n",
    "        if len(main_ent)>0:\n",
    "            #print(str(main_entity), len(c.mentions))\n",
    "            for ent in c.mentions:\n",
    "                res.append((main_ent, mapping[ent.start_char]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delimiter(paragraph,nlp(paragraph),\"sent\")\n",
    "# timeline(paragraph,\"sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historic Annapolis 0\n",
      "Kate Warren 11\n",
      "her rental car 0\n",
      "that guy 0\n",
      "the large circle circumscribing St. Anne's Church 0\n",
      "Tony Johnson 12\n",
      "never her precious boys 0\n",
      "the place where she had witnessed her step-father Ray 3\n",
      "Market Street 0\n",
      "The big car 0\n",
      "Her phone 0\n",
      "it 0\n",
      "He 0\n",
      "the house 0\n",
      "Matt and Jake 9\n",
      "the street 0\n",
      "a meager railing 0\n",
      "some of the more spectacular old houses in the district 0\n",
      "Annapolis's natural harbor 0\n",
      "the brake 0\n",
      "the hill 0\n",
      "each house 0\n",
      "people 0\n",
      "Annapolis 0\n",
      "Market Street 0\n",
      "the car 0\n",
      "Chris 5\n",
      "her cigarette 0\n",
      "Kate 4\n",
      "his 0\n",
      "her belly 0\n",
      "it 0\n",
      "\" the old lady 0\n",
      "it 0\n",
      "The terrier 0\n",
      "it 0\n",
      "the condemning old lady 0\n",
      "the baby 0\n",
      "they 0\n",
      "they 0\n",
      "old gargoyle McDonough 0\n",
      "we 0\n",
      "that spooky old house 0\n",
      "her family 0\n",
      "they 0\n",
      "her head 0\n",
      "pregnant couples 0\n",
      "My mother 0\n",
      "his daughter 0\n",
      "wouldn't 0\n",
      "the baby 0\n",
      "it 0\n",
      "her mom 0\n",
      "a cellphone 0\n",
      "the old Bakelite monstrosity 0\n"
     ]
    }
   ],
   "source": [
    "for ent in doc._.coref_clusters:\n",
    "    #main_ent = ent.main[-1]\n",
    "    main_ent = extract_main_entity(ent.main)\n",
    "    print(ent.main,len(main_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, VERB, amod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_entity(ent):\n",
    "    res = \"\"\n",
    "    for e in ent.ents:\n",
    "        if e.label_ == \"PERSON\":\n",
    "            res = res + e.text + \" \"\n",
    "    return res.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind : 3 possible values; verb, adjective, both\n",
    "# returns dict with two keys 'words' and 'dist'\n",
    "# @words : dict with keys representing different entities and value as list of related words (verb, adjective or both)\n",
    "# @dist : list of pairs of entities along with their distnce score\n",
    "def wordcloud(txt=\"\", kind=\"both\"):\n",
    "    doc = nlp(txt)\n",
    "    char_ref = {}  # mappping between start idx of a mention to its cluster head name\n",
    "    for ent in doc._.coref_clusters:\n",
    "        #main_ent = ent.main[-1]\n",
    "        main_ent = extract_main_entity(ent.main)\n",
    "        if len(main_ent)>0: \n",
    "            for c in ent.mentions:\n",
    "                if c[-1].pos_ in [\"NOUN\", \"PROPN\", \"PRON\", \"DET\"]:\n",
    "                    char_ref[c[-1].idx] = main_ent\n",
    "    \n",
    "    # get verbs for each character\n",
    "    verb = {}\n",
    "    for possible_subject in doc:\n",
    "        if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "            if possible_subject.idx in char_ref:\n",
    "                clus_name = char_ref[possible_subject.idx]\n",
    "                if clus_name not in verb:\n",
    "                    verb[clus_name] = []\n",
    "                verb[clus_name].append(possible_subject.head.lemma_)\n",
    "                \n",
    "    for possible_verb in doc:\n",
    "        if possible_verb.pos == VERB:\n",
    "            for possible_subject in possible_verb.children:\n",
    "                if possible_subject.dep == nsubj:\n",
    "                    if possible_subject.idx in char_ref:\n",
    "                    #if possible_subject._.in_coref:\n",
    "                        clus_name = char_ref[possible_subject.idx]\n",
    "                        #clus_name = possible_subject._.coref_clusters[0].main\n",
    "                        if clus_name not in verb:\n",
    "                            verb[clus_name] = []\n",
    "                        verb[clus_name].append(possible_verb.lemma_)\n",
    "                    #verbs.append(possible_verb)\n",
    "                    break\n",
    "    \n",
    "    # get adjectives for each mention for each character\n",
    "    adjectives = {}\n",
    "    for adj in doc:\n",
    "        if adj.dep == amod:\n",
    "            if adj.head.idx in char_ref:\n",
    "                clus_name = char_ref[adj.head.idx]\n",
    "                if clus_name not in adjectives:\n",
    "                    adjectives[clus_name] = []\n",
    "                adjectives[clus_name].append(adj.text) \n",
    "    res = {}\n",
    "    if kind==\"verb\":\n",
    "        res[\"words\"] = verb\n",
    "    elif kind==\"adjective\":\n",
    "        res[\"words\"] = adjectives\n",
    "    elif kind==\"both\":\n",
    "        both = verb.copy()\n",
    "        for k in adjectives:\n",
    "            tmp = both[k]\n",
    "            tmp.extend(adjectives[k])\n",
    "            both[k] = tmp\n",
    "        res[\"words\"] = both\n",
    "#     res[\"dist\"] = distance_Wordcloud(res[\"words\"])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': {'Kate Warren': ['hang',\n",
       "   'floor',\n",
       "   'grab',\n",
       "   'buy',\n",
       "   'think',\n",
       "   'pull',\n",
       "   'believe',\n",
       "   'go',\n",
       "   'be',\n",
       "   'turn',\n",
       "   'traverse',\n",
       "   'witness',\n",
       "   'imagine',\n",
       "   'see',\n",
       "   'be',\n",
       "   'want',\n",
       "   'slow',\n",
       "   'turn',\n",
       "   'glance',\n",
       "   'call',\n",
       "   'pull',\n",
       "   'have',\n",
       "   'snort',\n",
       "   'take',\n",
       "   'consider',\n",
       "   'sink',\n",
       "   'let',\n",
       "   'guess',\n",
       "   'realize',\n",
       "   'have',\n",
       "   'see',\n",
       "   'remember',\n",
       "   'live',\n",
       "   'parallel',\n",
       "   'drag',\n",
       "   'drag',\n",
       "   'wave',\n",
       "   'look',\n",
       "   'hang',\n",
       "   'floor',\n",
       "   'grab',\n",
       "   'buy',\n",
       "   'think',\n",
       "   'pull',\n",
       "   'believe',\n",
       "   'go',\n",
       "   'be',\n",
       "   'turn',\n",
       "   'traverse',\n",
       "   'witness',\n",
       "   'imagine',\n",
       "   'see',\n",
       "   'be',\n",
       "   'want',\n",
       "   'slow',\n",
       "   'turn',\n",
       "   'glance',\n",
       "   'call',\n",
       "   'pull',\n",
       "   'have',\n",
       "   'snort',\n",
       "   'take',\n",
       "   'consider',\n",
       "   'sink',\n",
       "   'let',\n",
       "   'guess',\n",
       "   'realize',\n",
       "   'have',\n",
       "   'see',\n",
       "   'remember',\n",
       "   'live',\n",
       "   'parallel',\n",
       "   'drag',\n",
       "   'drag',\n",
       "   'wave',\n",
       "   'look'],\n",
       "  'Tony Johnson': ['kiss', 'kiss'],\n",
       "  'Matt Jake': ['be', 'be'],\n",
       "  'Chris': ['show',\n",
       "   'say',\n",
       "   'sound',\n",
       "   'say',\n",
       "   'laugh',\n",
       "   'see',\n",
       "   'admit',\n",
       "   'say',\n",
       "   'have',\n",
       "   'say',\n",
       "   'tell',\n",
       "   'think',\n",
       "   'chuckle',\n",
       "   'do',\n",
       "   'say',\n",
       "   'chuckle',\n",
       "   'say',\n",
       "   'get',\n",
       "   'sigh',\n",
       "   'say',\n",
       "   'like',\n",
       "   'hang',\n",
       "   'make',\n",
       "   'be',\n",
       "   'show',\n",
       "   'say',\n",
       "   'sound',\n",
       "   'say',\n",
       "   'laugh',\n",
       "   'see',\n",
       "   'admit',\n",
       "   'say',\n",
       "   'have',\n",
       "   'say',\n",
       "   'tell',\n",
       "   'think',\n",
       "   'chuckle',\n",
       "   'do',\n",
       "   'say',\n",
       "   'chuckle',\n",
       "   'say',\n",
       "   'get',\n",
       "   'sigh',\n",
       "   'say',\n",
       "   'like',\n",
       "   'hang',\n",
       "   'make',\n",
       "   'be'],\n",
       "  'Kate': ['take',\n",
       "   'know',\n",
       "   'say',\n",
       "   'sigh',\n",
       "   'think',\n",
       "   'feel',\n",
       "   'be',\n",
       "   'take',\n",
       "   'shiver',\n",
       "   'tap',\n",
       "   'say',\n",
       "   'lie',\n",
       "   'say',\n",
       "   'smile',\n",
       "   'nod',\n",
       "   'erase',\n",
       "   'feel',\n",
       "   'grunt',\n",
       "   'guess',\n",
       "   'have',\n",
       "   'say',\n",
       "   'be',\n",
       "   'say',\n",
       "   'be',\n",
       "   'be',\n",
       "   'mutter',\n",
       "   'get',\n",
       "   'snort',\n",
       "   'huff',\n",
       "   'correct',\n",
       "   'know',\n",
       "   'feel',\n",
       "   'respond',\n",
       "   'let',\n",
       "   'turn',\n",
       "   'take',\n",
       "   'feel',\n",
       "   'know',\n",
       "   'sit',\n",
       "   'take',\n",
       "   'know',\n",
       "   'say',\n",
       "   'sigh',\n",
       "   'think',\n",
       "   'feel',\n",
       "   'be',\n",
       "   'take',\n",
       "   'shiver',\n",
       "   'tap',\n",
       "   'say',\n",
       "   'lie',\n",
       "   'say',\n",
       "   'smile',\n",
       "   'nod',\n",
       "   'erase',\n",
       "   'feel',\n",
       "   'grunt',\n",
       "   'guess',\n",
       "   'have',\n",
       "   'say',\n",
       "   'be',\n",
       "   'say',\n",
       "   'be',\n",
       "   'be',\n",
       "   'mutter',\n",
       "   'get',\n",
       "   'snort',\n",
       "   'huff',\n",
       "   'know',\n",
       "   'feel',\n",
       "   'respond',\n",
       "   'let',\n",
       "   'turn',\n",
       "   'take',\n",
       "   'feel',\n",
       "   'know',\n",
       "   'sit']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud(paragraph, \"verb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_doc = nlp(paragraph)\n",
    "new_txt = org_doc._.coref_resolved\n",
    "doc = nlp(new_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for possible_subject in doc:\n",
    "#     if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "#         print(possible_subject.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The cute Kate Warren is firing guns\"\n",
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind : 3 possible values; verb, adjective, both\n",
    "# returns dict with two keys 'words' and 'dist'\n",
    "# @words : dict with keys representing different entities and value as list of related words (verb, adjective or both)\n",
    "# @dist : list of pairs of entities along with their distnce score\n",
    "def wordcloud(txt=\"\", kind=\"both\"):\n",
    "#     doc = nlp(txt)\n",
    "    char_ref = {'Kate Warren':'Kate Warren', 'Kate':'Kate Warren', \n",
    "                'Chris': 'Chris'}  # mappping between start idx of a mention to its cluster head name\n",
    "    \n",
    "    # get verbs for each character\n",
    "    # get adjectives for each mention for each character\n",
    "    verb = {}\n",
    "    adjectives = {}\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_ == \"nsubj\" and token.head.pos_ == 'VERB':\n",
    "            main_ent = extract_main_entity(token.text, char_ref)\n",
    "            if token.text in char_ref:\n",
    "                clus_name = char_ref[token.text]\n",
    "                if clus_name not in verb:\n",
    "                    verb[clus_name] = []\n",
    "                verb[clus_name].append(token.head.lemma_)\n",
    "                \n",
    "            elif (main_ent) and (main_ent in char_ref) :\n",
    "                clus_name = char_ref[main_ent]\n",
    "                if clus_name not in verb:\n",
    "                    verb[clus_name] = []\n",
    "                verb[clus_name].append(token.head.lemma_)\n",
    "                \n",
    "        if token.dep_ == \"amod\":\n",
    "            main_ent = extract_main_entity(token.head.text, char_ref)\n",
    "#             print(token.text, token.dep_, token.head.text, main_ent)\n",
    "            if token.head.text in char_ref:\n",
    "                clus_name = char_ref[token.head.text]\n",
    "                if clus_name not in adjectives:\n",
    "                    adjectives[clus_name] = []\n",
    "                adjectives[clus_name].append(token.text)\n",
    "                \n",
    "            elif (main_ent) and (main_ent in char_ref):\n",
    "                print(\"entered\")\n",
    "                clus_name = char_ref[main_ent]\n",
    "                if clus_name not in adjectives:\n",
    "                    adjectives[clus_name] = []\n",
    "                adjectives[clus_name].append(token.text) \n",
    "#         \n",
    "#     print(adjectives)\n",
    "    res = {}\n",
    "    if kind==\"verb\":\n",
    "        res[\"words\"] = verb\n",
    "    elif kind==\"adjective\":\n",
    "        res[\"words\"] = adjectives\n",
    "    elif kind==\"both\":\n",
    "        both = verb.copy()\n",
    "        for k in adjectives:\n",
    "            tmp = both[k]\n",
    "            tmp.extend(adjectives[k])\n",
    "            both[k] = tmp\n",
    "        res[\"words\"] = both\n",
    "#     res[\"dist\"] = distance_Wordcloud(res[\"words\"])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'words': {'Kate Warren': ['hang',\n",
       "   'floor',\n",
       "   'grab',\n",
       "   'think',\n",
       "   'pull',\n",
       "   'believe',\n",
       "   'turn',\n",
       "   'traverse',\n",
       "   'witness',\n",
       "   'imagine',\n",
       "   'see',\n",
       "   'be',\n",
       "   'want',\n",
       "   'vomit',\n",
       "   'slow',\n",
       "   'turn',\n",
       "   'glance',\n",
       "   'pull',\n",
       "   'have',\n",
       "   'snort',\n",
       "   'take',\n",
       "   'consider',\n",
       "   'let',\n",
       "   'guess',\n",
       "   'realize',\n",
       "   'have',\n",
       "   'see',\n",
       "   'remember',\n",
       "   'live',\n",
       "   'parallel',\n",
       "   'drag',\n",
       "   'be',\n",
       "   'drag',\n",
       "   'wave',\n",
       "   'look',\n",
       "   'take',\n",
       "   'know',\n",
       "   'say',\n",
       "   'sigh',\n",
       "   'think',\n",
       "   'feel',\n",
       "   'be',\n",
       "   'take',\n",
       "   'shiver',\n",
       "   'tap',\n",
       "   'say',\n",
       "   'lie',\n",
       "   'say',\n",
       "   'smile',\n",
       "   'nod',\n",
       "   'erase',\n",
       "   'feel',\n",
       "   'grunt',\n",
       "   'guess',\n",
       "   'have',\n",
       "   'say',\n",
       "   'be',\n",
       "   'say',\n",
       "   'be',\n",
       "   'be',\n",
       "   'mutter',\n",
       "   'get',\n",
       "   'snort',\n",
       "   'huff',\n",
       "   'correct',\n",
       "   'know',\n",
       "   'feel',\n",
       "   'respond',\n",
       "   'let',\n",
       "   'turn',\n",
       "   'take',\n",
       "   'feel',\n",
       "   'know',\n",
       "   'sit'],\n",
       "  'Chris': ['show',\n",
       "   'say',\n",
       "   'sound',\n",
       "   'say',\n",
       "   'laugh',\n",
       "   'see',\n",
       "   'admit',\n",
       "   'say',\n",
       "   'have',\n",
       "   'say',\n",
       "   'tell',\n",
       "   'think',\n",
       "   'chuckle',\n",
       "   'do',\n",
       "   'say',\n",
       "   'chuckle',\n",
       "   'say',\n",
       "   'get',\n",
       "   'sigh',\n",
       "   'say',\n",
       "   'like',\n",
       "   'hang',\n",
       "   'make',\n",
       "   'be']}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud(paragraph, \"verb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
